{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbsjLt_NoYWy"
   },
   "source": [
    "# Predicting Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tzgFCjeL7VkL"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, utils, datasets\n",
    "from tqdm import tqdm\n",
    "from torch.nn.parameter import Parameter\n",
    "import pdb\n",
    "import torchvision\n",
    "import os\n",
    "import gzip\n",
    "import tarfile\n",
    "import gc\n",
    "from IPython.core.ultratb import AutoFormattedTB\n",
    "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_NFK_oboYr8"
   },
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class SatelliteDataset(Dataset):\n",
    "  def __init__(self, size=256, train=True):\n",
    "    self.train = train\n",
    "    self.size = size\n",
    "    self.root = os.getcwd() + \"/drive/MyDrive/Deep Learning Project\"\n",
    "\n",
    "  def __getitem__(self,index):\n",
    "    \n",
    "    return img[0],label[0][0]\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.dataset_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhmmrBS37VkO"
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, up_sample=False):\n",
    "    super(ConvBlock, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels, out_channels, (3,3), padding=(1,1))\n",
    "    self.conv2 = nn.Conv2d(out_channels, out_channels, (3,3), padding=(1,1))\n",
    "    self.up_sample = up_sample\n",
    "    if up_sample:    \n",
    "      # Up sample with up-conv 2x2, doubling along each dimension\n",
    "      self.up = nn.ConvTranspose2d(out_channels, out_channels//2, 2, stride=2)\n",
    "    # We do not want to down sample in the block, since we need the non-down-sampled output for skip connections\n",
    "\n",
    "  def forward(self, input):\n",
    "    x = F.relu(self.conv1(input))\n",
    "    x = F.relu(self.conv2(x))\n",
    "    if self.up_sample:\n",
    "      x = self.up(x)\n",
    "    return x\n",
    "\n",
    "class SatelliteDetection(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SatelliteDetection, self).__init__()\n",
    "    # Downsample convolution blocks\n",
    "    self.dblock1 = ConvBlock(3, 64)\n",
    "    self.dblock2 = ConvBlock(64, 128)\n",
    "    self.dblock3 = ConvBlock(128, 256)\n",
    "    self.dblock4 = ConvBlock(256, 512)\n",
    "    # Upsample convolution blocks\n",
    "    self.ublock1 = ConvBlock(512, 1024, True)\n",
    "    # The next 4 blocks have doubled input channels due to concatination of skip connections\n",
    "    self.ublock2 = ConvBlock(1024, 512, True)\n",
    "    self.ublock3 = ConvBlock(512, 256, True)\n",
    "    self.ublock4 = ConvBlock(256, 128, True)\n",
    "    # Output \"block\"\n",
    "    self.convf1 = nn.Conv2d(128, 64, (3,3), padding=(1,1))\n",
    "    self.convf2 = nn.Conv2d(64, 64, (3,3), padding=(1,1))\n",
    "    self.convf3 = nn.Conv2d(64, 2, (1,1), padding=(0,0))\n",
    "\n",
    "    self.down = nn.MaxPool2d(2)\n",
    " \n",
    "  def forward(self, input):\n",
    "    # Save the last feature maps on each level! Pass an instance forward, but keep the variable referencing the same feature map for concatenation\n",
    "    l1 = self.dblock1(input)\n",
    "    l2 = self.dblock2(self.down(l1))\n",
    "    l3 = self.dblock3(self.down(l2))\n",
    "    l4 = self.dblock4(self.down(l3))\n",
    "    # Concatinate l1 - l4 on inputs across the U in reverse order, matching sizes\n",
    "    u = self.ublock1(self.down(l4))\n",
    "    u = self.ublock2(torch.cat((l4, u), dim=1))\n",
    "    u = self.ublock3(torch.cat((l3, u), dim=1))\n",
    "    u = self.ublock4(torch.cat((l2, u), dim=1))\n",
    "    out = F.relu(self.convf1(torch.cat((l1, u), dim=1)))\n",
    "    out = F.relu(self.convf2(out))\n",
    "    out = self.convf3(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZXpcWB_7VkQ"
   },
   "outputs": [],
   "source": [
    "# Initialize Datasets\n",
    "train_dataset = SatelliteDataset(train=True, size=96)\n",
    "val_dataset = SatelliteDataset(train=False, size=96)\n",
    "\n",
    "# Grab test image and label\n",
    "test_im, test_gt = val_dataset[172]\n",
    "# Give test image a batch dim of 1 and put on GPU\n",
    "test_im = test_im.unsqueeze(0).cuda()\n",
    "\n",
    "# Initialize Model\n",
    "model = SatelliteDetection()\n",
    "model.cuda()\n",
    "\n",
    "# Initialize Objective and Optimizer and other parameters\n",
    "objective = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVWmwLEp7VkR"
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "train_accs_pw = []\n",
    "val_accs_pw = []\n",
    "test_preds = []\n",
    "\n",
    "import time\n",
    "\n",
    "def scope():\n",
    "  try:\n",
    "    #your code for calling dataset and dataloader\n",
    "    gc.collect()\n",
    "    print(torch.cuda.memory_allocated(0) / 1e9)\n",
    "\n",
    "    # Initialize DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=6, pin_memory=True, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=6, pin_memory=True, shuffle=True)\n",
    "\n",
    "    # Call your model, figure out loss and accuracy\n",
    "\n",
    "    # get the mean of losses from running the validation loader\n",
    "    vals = []\n",
    "    val_a = []\n",
    "    val_a_pw = 0\n",
    "    with torch.no_grad():\n",
    "      for x, y_truth in val_loader:\n",
    "        gc.collect()\n",
    "        x, y_truth = x.cuda(), y_truth.cuda() \n",
    "        y_hat = model(x.cuda())\n",
    "        vals.append(objective(y_hat, y_truth.long()).item())\n",
    "        iou = IoU(torch.softmax(y_hat,1), y_truth.float())\n",
    "        val_a_pw += pixelwise_accuracy(y_hat, y_truth).sum().item()\n",
    "        if iou != -1:\n",
    "          val_a.append(iou)\n",
    "      val_losses.append((len(train_losses), np.mean(vals)))\n",
    "      val_accs.append((len(train_losses), np.mean(val_a)))\n",
    "      val_accs_pw.append(val_a_pw / len(val_dataset))\n",
    "\n",
    "    num_epochs = 5\n",
    "    for epoch in range(num_epochs):\n",
    "      loop = tqdm(total=len(train_loader), position=0, leave=False)\n",
    "\n",
    "      for batch, (x, y_truth) in enumerate(train_loader):\n",
    "        gc.collect()\n",
    "        x, y_truth = x.cuda(), y_truth.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x)\n",
    "\n",
    "        loss = objective(y_hat, y_truth.long())\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        train_acc = IoU(torch.softmax(y_hat, 1), y_truth.float())\n",
    "        if train_acc != -1:\n",
    "          train_accs.append(train_acc)\n",
    "          train_accs_pw.append(pixelwise_accuracy(y_hat, y_truth).mean())\n",
    "        loop.set_description('epoch:{0}, loss{1:.4f}, accuracy:{2:.3f}'.format(epoch, loss.item(), train_acc))\n",
    "        loop.update(1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "      # get the mean of losses from running the validation loader\n",
    "      vals = []\n",
    "      val_a = []\n",
    "      val_a_pw = 0\n",
    "      with torch.no_grad():\n",
    "        for x, y_truth in val_loader:\n",
    "          gc.collect()\n",
    "          x, y_truth = x.cuda(), y_truth.cuda() \n",
    "          y_hat = model(x.cuda())\n",
    "          vals.append(objective(y_hat, y_truth.long()).item())\n",
    "          iou = IoU(torch.softmax(y_hat,1), y_truth.float())\n",
    "          val_a_pw += pixelwise_accuracy(y_hat, y_truth).sum().item()\n",
    "          if iou != -1:\n",
    "            val_a.append(iou)\n",
    "        val_losses.append((len(train_losses), np.mean(vals)))\n",
    "        val_accs.append((len(train_losses), np.mean(val_a)))\n",
    "        val_accs_pw.append(val_a_pw / len(val_dataset))\n",
    "\n",
    "        # Collect predictions on the test image\n",
    "        test_preds.append(model(test_im).cpu())\n",
    "\n",
    "      loop.close()\n",
    "      \n",
    "    \n",
    "  except:\n",
    "    __ITB__()\n",
    "    \n",
    "begin = time.time()\n",
    "scope()\n",
    "print(\"Runtime =\", time.time()-begin)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SIML_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
